{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5 - Convolutional Neural Networks\n",
    "\n",
    "In this lab you'll use [PyTorch](https://pytorch.org/) to:\n",
    "* train a *convolutional neural network* (CNN, or ConvNet) on <u>1D synthetic data</u> and on <u>2D real data</u>;\n",
    "* learn how to inspect the filters and the feature maps of your model, to ensure you understand the inner workings (intermediate representations) that are computed during the feed-forward computation of a ConvNet;\n",
    "* learn how a ConvNet training can get stuck in a local minimum, and how increasing the number of filters helps.\n",
    "\n",
    "If you really want to understand convolutions in detail, you can also download the *convolution_layer_demo.zip* file in the course Moodle page and run the Jupyter notebook inside. (All the code in that notebook is done for you.)\n",
    "\n",
    "**Run the code cell below** to import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import copy\n",
    "np.set_printoptions(precision=3, suppress=True)  # Print as 0.001 instead of 9.876e-4\n",
    "torch.set_printoptions(precision=3, sci_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the code cell below** to define a plotting function that is useful for visualizing the weights of neural networks and images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix_grid(V, cmap='bwr'):\n",
    "    \"\"\"\n",
    "    Given an array V containing stacked matrices, plots them in a grid layout.\n",
    "    V should have shape (K,M,N) where V[k] is a matrix of shape (M,N).\n",
    "    The default cmap is \"bwr\" (blue-white-red) but can also be \"gray\".\n",
    "    \"\"\"\n",
    "    if isinstance(V, torch.Tensor):\n",
    "        V = V.detach().numpy()\n",
    "    assert V.ndim == 3, \"Expected V to have 3 dimensions, not %d\" % V.ndim\n",
    "    k, m, n = V.shape\n",
    "    ncol = 8                                     # At most 8 columns\n",
    "    nrow = min(4, (k + ncol - 1) // ncol)        # At most 4 rows\n",
    "    V = V[:nrow*ncol]                            # Focus on just the matrices we'll actually plot\n",
    "    figsize = (2*ncol, max(1, 2*nrow*(m/n)))     # Guess a good figure shape based on ncol, nrow\n",
    "    fig, axes = plt.subplots(nrow, ncol, sharex=True, sharey=True, figsize=figsize)\n",
    "    vmax = np.percentile(np.abs(V), [99.9])      # Show the main range of values, between 0.1%-99.9%\n",
    "    for v, ax in zip(V, axes.flat):\n",
    "        img = ax.matshow(v, vmin=-vmax, vmax=vmax, cmap=plt.get_cmap(cmap))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    for ax in axes.flat[len(V):]:\n",
    "        ax.set_axis_off()\n",
    "    fig.colorbar(img, cax=fig.add_axes([0.92, 0.25, 0.01, .5]))   # Add a colorbar on the right    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# 1. Convolutional Neural Networks on Synthetic Data\n",
    "\n",
    "Exercise 1.1&ndash;1.4 ask you to generate a synthetic data set and to inspect how a 1D convolutional neural network learns \"pattern detectors\" on it. <u>Building a toy synthetic dataset is good practice when sanity-checking a model that you have never worked with</u>. It will be easy to plot all the features, targets, and predictions all at once.\n",
    "\n",
    "**Run the code cell below** to define a function that will be able to plot your synthetic training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_named_tensors(tensor_dict):\n",
    "    \"\"\"\n",
    "    Given a dict of {name: tensor} pairs, plots the tensors side-by-side in a common\n",
    "    color scale. The name of each tensor is shown above its plot.\n",
    "    \"\"\"\n",
    "    n = len(tensor_dict)\n",
    "    vmax = max(v.abs().max() for v in tensor_dict.values())\n",
    "    figsize = (2*n, 6)\n",
    "    fig, axes = plt.subplots(1, n, figsize=figsize,  constrained_layout=True, squeeze=True)\n",
    "    axes = axes.flat if isinstance(axes, np.ndarray) else (axes,)\n",
    "    for (name, v), ax in zip(tensor_dict.items(), axes):\n",
    "        v = torch.squeeze(v.detach())   # Automatically convert (N,1,D) to (N,D)\n",
    "        if v.ndim == 1:\n",
    "            v = v.view(-1, 1)  # Automatically convert (N,) to (N,1)\n",
    "        assert v.ndim == 2, \"couldn't turn tensors[%d] with shape %s into 2D\" % (i, v.shape)\n",
    "        img = ax.matshow(v, vmin=-vmax, vmax=vmax, cmap=plt.get_cmap('bwr'))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title(name)\n",
    "    fig.colorbar(img, cax=fig.add_axes([0.985, 0.25, 0.03, .5]))   # Add a colorbar on the right    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.1 &ndash; Build a synthetic 1D data set\n",
    "\n",
    "Start by building a synthetic training set $\\{(\\mathbf{x}_i, y_i)\\}_{i=1}^N$, where the goal is to \"detect pattern $[0,1,0]$ in the input\". \n",
    " * Each input $\\mathbf{x}_i \\in \\mathbb{R}^{20}$ represents a single-channel 1-dimensional 'image' of width $W=20$ having values from $\\{-1, -\\frac{1}{2}, 0, \\frac{1}{2}, 1\\}$. This means that each input is a vector of 20 elements that can only contain -1, -0.5, 0, 0.5, or 1 as possible values.\n",
    " * Each target $y_i \\in \\{0, 1\\}$ represents a class label, with $y_i=1$ if the subsequence $[0,1,0]$ appears somewhere in $\\mathbf{x}_i$.\n",
    " * The dataset should have $N=75$ items. \n",
    "\n",
    "In order to apply [**torch.nn.Conv1d**](https://pytorch.org/docs/stable/nn.html#torch.nn.Conv1d) module to the inputs, you'll need to represent them in a single tensor having \"$(N,C,W)$ format\", which here means $\\mathbf{X} \\in \\mathbb{R}^{75 \\times 1 \\times 20}$. Likewise you'll need the targets to have shape $\\mathbf{y} \\in \\mathbb{R}^{75 \\times 1}$.  \n",
    "\n",
    "Specific steps to build $\\mathbf{X}$ and $\\mathbf{y}$, that you will have to implement in Python:\n",
    "1. Create $\\mathbf{X}$ and $\\mathbf{y}$ as torch tensors full of zeros.\n",
    "2. For each row $i=0,\\ldots,N-1$:\n",
    "   1. Sample a random integer $\\text{size} \\in \\{1,2\\}$, _i.e._ the size of the subrange of pixels that will be assigned. You can use here [**np.random.randint**](https://numpy.org/doc/stable/reference/random/generated/numpy.random.randint.html). Note that the *randint(a,b)* returns an integer strictly less than *b*.\n",
    "   2. Sample a random integer $\\text{start} \\in \\{0,\\ldots,W-\\text{size}-1\\}$, _i.e._ the offset from the start of the image.\n",
    "   3. Sample a random choice $\\text{value} \\in \\{-1, -\\frac{1}{2}, \\frac{1}{2}, 1\\}$, _i.e._ the value to fill for the subrange. You can use here [**np.random.choice**](https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html).\n",
    "   4. Assign a stretch of features $X[i,0, \\text{start}:\\text{start}+\\text{size}] = \\text{value}$, which will either be size 1 or 2. Basically, if the size is 1 we are going to replace a single value (i.e., if we sample 0.5, the current input vector will be something like [0,0,...,0,0.5,0,...0,0]). If the size is 2, we append 2 times the same value in consecutive indexes (i.e., if we sample 0.5, we will have $[0,..., 0, 0.5, 0.5, 0, ...,0]$ in the current input vector.\n",
    "   5. Assign target $y[i]$ to be 1 if both $\\text{size}=1$ and $\\text{value} = +1$, _i.e._ if $X[i,0,:]$ has a single \"+1\" pixel somewhere in it.\n",
    "\n",
    "**Complete the starter code below** by completing the for loop. <span style=\"color:red\">If PyTorch complains about not being able to convert *numpy.int32* or *numpy.bool_* to *torch.FloatTensor* you may need to explicitly convert the value to float using *float(value)*.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)  # For reproducibility\n",
    "\n",
    "N = 75  # N = number of training cases\n",
    "C = 1   # C = number of channels (just 1 in our case)\n",
    "W = 20  # W = width of the 1-dimensional input image\n",
    "\n",
    "# We create feature tensor X in \"(N,C,W) format\" (the shape) so that it can\n",
    "# be used directly as input to PyTorch's Conv1D module.\n",
    "X = torch.zeros((N, C, W))   # Start with zeros. You need to assign some of these feature values!\n",
    "y = torch.zeros((N, 1))      # Start with zeros. You need to assign some of these target values!\n",
    "\n",
    "for i in range(N):\n",
    "    # Your code for initializing X and y here. Aim for 5-7 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check your answer** by running the code cell below. It will plot the entire training set as a heatmap, where blue indicates negative values and red indicates positive values. If you initialized your training set correctly (and kept `np.random.seed(0)` above) you should see exactly this training set:\n",
    "![image](img/synthetic_training_set.png)\n",
    "Here we have $N=75$ rows and $W=20$ columns shown for the $\\mathbf{X}$ tensor. Notice that the red dots in the $\\mathbf{y}$ vector correspond to the $y_i=1$ for which there is exactly a 1-pixel red dot (a $+1$) in the corresponding input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_named_tensors({'X': X, 'y': y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.2 &ndash; Define a ConvNet architecture suitable for classifing your synthetic data\n",
    "\n",
    "\n",
    "You are asked to define a 1D convolutional neural network with the following feed-forward architecture built from the [PyTorch modules](https://pytorch.org/docs/stable/nn.html) mentioned. The architecture should transform an input tensor $X \\in \\mathbb{R}^{N \\times C \\times W}$ into a vector of scalar activations $\\mathbf{a} \\in \\mathbb{R}^{N \\times 1}$. \n",
    "\n",
    "![image](img/conv1d_architecture.png)\n",
    "\n",
    "Comments on the architecture:\n",
    "* The *convolutional* layer is depicted as having exactly enough padding (implicitly zero) to ensure that the output feature maps have the same spatial length ($W=20$) as the input vector had. Notice that if you were to increase the filter size by 2, you need to increase the padding by 1 (padding appears on both ends) to keep the output of convolution the same length as before. See the documentation for the Conv1d module.\n",
    "* The *max pooling* layer is being used here to take the maximum value across each of the 3 feature maps shown. Since we want to take the max over the entire spatial extent of the feature map, we use a large *kernel_size*.\n",
    "* The 1-dimensional convolution and pooling operations require *spatial* data in $(N,C,W)$ format (where $W$ is the spatial dimension), so that the operators know how long the spatial dimension is. However the *linear* (fully-connected) layer doesn't know how to deal with spatial data, so the *flatten* operation simply reshapes the tensor from shape $(N,C,W)$ to shape $(N,D)$ where $D=C \\times W$.\n",
    "* Even though we'll use this architecture for binary classification, we do not add an extra *sigmoid* operation directly to the output. This is done for same reasons as for the multi-class PyTorch neural network from Lab 4. After the model is defined, we can still use it to predict binary class probabilities $\\hat{y}_i \\in [0,1]$ by feeding features $X$ through the model and then feeding the resulting activations $\\mathbf{a}$ through a sigmoid so that class predictions are $\\mathbf{\\hat{y}} = \\sigma(\\mathbf{a})$. \n",
    "\n",
    "**Add a few lines of code** to define a PyTorch model with the above architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0) # Ensure model weights initialized with same random numbers\n",
    "\n",
    "num_filter = 3   # The number of filters to learn\n",
    "filter_size = 5  # The size of each filter\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    # Your code for defining the model architecture here. Aim for 5-9 lines.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check your model architecture** by running the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(model) == 5, \"Should be 5 layers!\"\n",
    "assert isinstance(model[0], torch.nn.Conv1d), \"layer 0 should be Conv1d\"\n",
    "assert model[0].in_channels == C, \"layer 0 should expect C input channel\"\n",
    "assert model[0].out_channels == num_filter, \"layer 0 should expect %d output channels\" % num_filter\n",
    "assert model[0].kernel_size[0] == filter_size, \"layer 0 filter size should be %d\" % filter_size\n",
    "assert model[0].padding[0] == filter_size//2\n",
    "assert isinstance(model[1], torch.nn.ReLU), \"layer 1 should be ReLU\"\n",
    "assert isinstance(model[2], torch.nn.MaxPool1d), \"layer 2 should be MaxPool1d\"\n",
    "assert model[2].kernel_size == W, \"layer 2 should pool over the entire input feature map\"\n",
    "assert isinstance(model[3], torch.nn.Flatten), \"layer 3 should by Flatten\"\n",
    "assert isinstance(model[4], torch.nn.Linear), \"layer 4 should be Linear\"\n",
    "assert model[4].in_features == num_filter, \"layer 4 should have accept %d inputs\" % num_filter\n",
    "assert model[4].out_features == 1, \"layer 4 should have only 1 output\"\n",
    "print(\"Looks OK!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot your model's initial predictions** (i.e. *before* training) by running the code cell below. Notice that the untrained model predicts arbitrary class probabilies that all look similar. This is because the initial weights of the Conv1d and Linear layers are small random values, so the output is only weakly sensitive to the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.sigmoid(model(X))   # Turn activations into probabilities by feeding through sigmoid\n",
    "print(y_pred[:5])                  # Print the first few probabilities\n",
    "plot_named_tensors({'X': X, '$\\hat{y}$': y_pred, 'y': y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.3 &ndash; Train the ConvNet on your synthetic data\n",
    "\n",
    "Here you should train the ConvNet architecture from Exercise 1.2, much as you trained a PyTorch neural network in the Lab 4.\n",
    "\n",
    "First, **run the code cell below** to make a copy of the untrained model from Exercise 1.2. This will make it easy to re-run the training code cell multiple times, each time starting from an untrained model (rather than continuing to train the same model!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained_model = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you'll need to define a loss function and implement a standard PyTorch training loop to train a copy of the untrained model. The PyTorch training loop for a ConvNet is identical to that of a neural network, so use Lab 4 as a guide.\n",
    "\n",
    "However, for this exercise use the following configuration:\n",
    "* *No mini-batches:* Unlike Lab 4, for this exercise do not use mini-batches. Instead feed the whole $X$ matrix through your model, like `model(X)` to get $N=75$ outputs. In other words, your training loop doesn't need an inner \"mini-batch\" loop.\n",
    "* *Loss function:* Use the \"binary cross entropy\" loss that directly accepts activations (i.e, the output of the model before applying the sigmoid. This output is called 'logits'). In PyTorch this is implemented by the **[torch.nn.BCEWithLogitsLoss](https://pytorch.org/docs/stable/nn.html#torch.nn.BCEWithLogitsLoss)** module. This is similar to the *CrossEntropyLoss* in Lab 4, except it's specialized to handle a single binary output.\n",
    "* *Optimizer:* This is the learning algorithm. Use the **[torch.optim.SGD](https://pytorch.org/docs/stable/optim.html#torch.optim.SGD)** optimizer with learning rate $0.05$, momentum $0.9$, and weight decay (weight penalty) of $0.001$.\n",
    "\n",
    "Your training code should also print the current training loss for the first epoch and every 50 epochs after. For example, if you computed your loss in variable `loss_value` then something like this would work:\n",
    "```python\n",
    "for epoch in range(1, num_epoch+1):\n",
    "    \n",
    "    ... your code to apply a step of gradient descent here\n",
    "    \n",
    "    if epoch == 1 or epoch % 50 == 0:\n",
    "        print(\"Epoch %d had training loss %.4f\" % (epoch, loss_value.item()))\n",
    "```\n",
    "where the `.item()` is a method that converts a scalar-valued PyTorch tensor into a standard Python value, like a *float*, so that it can be more easily formatted as part of the string.\n",
    "\n",
    "The output of your training loop should look exactly like this:\n",
    "```\n",
    "Epoch 1 had training loss 0.8562\n",
    "Epoch 50 had training loss 0.3519\n",
    "Epoch 100 had training loss 0.3281\n",
    "Epoch 150 had training loss 0.3212\n",
    "...\n",
    "```\n",
    "However, the loss should not go to zero for the current model architecture. You'll fix that shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start from a copy of the untrained model, so that when we re-run this code\n",
    "# cell it always resets to the beginning.\n",
    "model = copy.deepcopy(untrained_model)\n",
    "\n",
    "# The number of times to evaluate the full training data (in this case, number of gradient steps)\n",
    "num_epoch = 500\n",
    "\n",
    "# Your code for defining loss and optimizer. Aim 2 lines.\n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=1e-3)\n",
    "\n",
    "for epoch in range(1, num_epoch+1):\n",
    "    \n",
    "    # Your code for defining the training loop. Aim 7-9 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot your trained model's predictions** in the code cell below. You should see that the prediction vector has an interesting pattern now (unlike the initial model), but that the predictions still do not quite match the targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here. See Exercise 1.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mismatch between predictions and targets is why the loss did not get close to zero, despite the fact that your ConvNet architecture can, in principle, learn a perfect classifier.\n",
    "\n",
    "If your model architecture was able to get the training loss to zero, the predictions would look more like this:\n",
    "\n",
    "![image](img/synthetic_predictions.png)\n",
    "\n",
    "<span style=\"color:red\">Currently,  your ConvNet training got stuck in a local minimum!</span>\n",
    "To give your ConvNet architecture a better chance at \"getting lucky\" and finding a path from random weights to useful weights, **try going back to Exercise 1.2 and increase the number of filters from 3 to 4**. You will then have to re-run all the code cells up to this point. With an extra filter, your ConvNet is now \"lucky\" enough to find at least one filter that detects a $0,1,0$ pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.4 Inspect the filters and weights of your ConvNet\n",
    "\n",
    "Here you should visualize both the filter weights and the linear (fully-connected) weights. Use the *plot_matrix_grid* function. If you managed to get your training loss to be small (close to zero) then at least one of your filters should look like this:\n",
    "\n",
    "![image](img/synthetic_filter_example.png)\n",
    "\n",
    "where red means positive and blue means negative. When this filter is convolved with a sequence containing pattern $\\ldots,0,1,0,\\ldots$ it will \"activate\" and have a large output at the position centered on the $1$. That activation then gets selected by the max pooling operation, and is then used to activate the output of the network, giving correct classification.\n",
    "\n",
    "**Write a few lines of plotting code** to visualize the weights of both layers. Do you see a correspondence between the filter that looks \"right\" and the positive weight(s) in the linear layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1, b1, W2, b2 = model.parameters()\n",
    "print(W1.shape)  # The tensor of 4 filters, each with 1 channel and kernel size 5\n",
    "print(W2.shape)  # The matrix of linear (fully-connected) weights that combine the filter responses\n",
    "\n",
    "# Your plotting code here. Aim for 2-4 lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# 2. Digit classification with Convolutional Neural Networks\n",
    "\n",
    "Exercise 2.1&ndash;2.2 expand on Lab 4, this time asking you to train a convolutional neural network on the MNIST data set rather than a fully-connected neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.1 Load and preprocess MNIST\n",
    "\n",
    "**Implement the *load_mnist_for_convnet* function** below. Rather than normalizing the features with scikit-learn, perform a simple normalization by scaling the pixel intensities from range $[0,255]$ down to $[0,1]$. This will be good enough. Remember to reshape the input to have a tensor with dimensionality $(N,1,28,28)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_mnist_for_convnet(filename):\n",
    "    \"\"\"\n",
    "    Loads the MNIST data from a Numpy NPZ file and returns two PyTorch tensors:\n",
    "    X: a float tensor with shape (N,1,28,28) where N is the number of images in the file\n",
    "    y: an int64 tensor with shape (N,) containing the class targets for the images.\n",
    "    The pixels values are scaled to be in range [0,1] where 0 is black and 1 is white.\n",
    "    \"\"\"\n",
    "    # Your code here. Aim for 7-10 lines.\n",
    "\n",
    "    return torch.from_numpy(X), torch.from_numpy(y)\n",
    "\n",
    "X_trn, y_trn = load_mnist_for_convnet(\"mnist_train.npz\")\n",
    "X_tst, y_tst = load_mnist_for_convnet(\"mnist_test.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check your answer** by running the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(X_trn, torch.FloatTensor), \"Features should be float32!\"\n",
    "assert isinstance(y_trn, torch.LongTensor), \"Targets should be int64 or long!\"\n",
    "assert X_trn.shape == (60000, 1, 28, 28), \"X_trn has wrong shape\"\n",
    "assert y_trn.shape == (60000,), \"y_trn has wrong shape\"\n",
    "assert X_tst.shape == (10000, 1, 28, 28), \"X_tst has wrong shape\"\n",
    "assert y_tst.shape == (10000,), \"y_tst has wrong shape\"\n",
    "assert X_trn.min() == 0 and X_trn.max() == 1, \"Features don't seem to be scaled right!\"\n",
    "print(\"Looks good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "\n",
    "## Exericise 2.2 Train a Convolutional Neural Network on MNIST\n",
    "\n",
    "You are asked to train a 2D ConvNet to classify MNIST digits. You'll need the *Conv2d* and *MaxPool2d* modules as described in the [PyTorch modules documentation](https://pytorch.org/docs/stable/nn.html). Your architecture will be similar to Part 1 of this lab, except rather than pooling over the entire input signal you will pool only over small 2x2 regions, preserving more spatial information for the subsequent linear (fully-connected) layer to use in classification.\n",
    "\n",
    "**Write a few lines of code** to define a 2D ConvNet with the following feed-forward architecture:\n",
    "1. Convolution with 8 filters each of size 5x5 and enough padding to ensure that each of the resulting feature maps has spatial dimensions 28x28, just like the input.\n",
    "2. Rectified linear transformation (ReLU).\n",
    "3. Max pooling with kernel size 2x2 and a non-overlapping stride (i.e. stride same as kernel size).\n",
    "4. Flatten the spatial information\n",
    "5. Linear (fully-connected) layer to use all the outputs of the max pooling layer as features to make a prediction.\n",
    "\n",
    "the output. As done before for the sigmoid, do not add the softmax here (because the categorical cross-entropy lossrequires 'logits' in input). \n",
    "\n",
    "Hint: the trickiest part is to correctly calculate the expected number of in_features for the linear layer. After the flattening operation, the number of inputs depends on the number of filters, original image size (28x28), and pool size (2x2). The number of output classes is 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0) # Ensure model weights initialized with same random numbers\n",
    "\n",
    "num_filters = 8\n",
    "filter_size = 5\n",
    "pool_size = 2\n",
    "\n",
    "# Your code here. Aim for 9-10 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check your model architecture** by trying to feed some inputs through. If an error is raised, then something is mis-configured in your network. The most likely error is that you did not correctly calculate the expected number of *in_features* for the linear layer, leading to a \"size mismatch\" in the tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(X_trn[:5])  # Check model architecture by trying to feed inputs through it.\n",
    "assert y_pred.shape == (5, 10), \"Expected a batch of 5 images to produce output of shape (5, 10)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot your initial model's predictions** on the first 50 training inputs by running the code cell below. Notice that once again all the predictions are pretty much the same, and are far from the targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed the model's predictions on 30 training cases through a row-wise softmax.\n",
    "y_pred = torch.softmax(model(X_trn[:50]), dim=1)\n",
    "\n",
    "# Convert the first 30 training targets from index format {0,...,9} to a 1-hot format,\n",
    "# for easier side-by-side comparison with the 10-dimensional output prediction.\n",
    "y_true = torch.zeros((50, 10))\n",
    "y_true[torch.arange(50), y_trn[:50]] = 1\n",
    "\n",
    "plot_named_tensors({'$\\hat{y}$': y_pred, '$y$': y_true})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspect your initial model's filters** by plotting them with the *plot_matrix_grid* function. They should look random and have small values roughly in range $[-0.1, 0.1]$ (Only plot the first layer filter weights, not the linear layer weights). As before, you can get the parameters with *model.parameters()*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your plotting code here. Aim for 1-2 lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train your model** with the following configuration:\n",
    "* Use the *CrossEntropyLoss* (since this is multi-class classification, not binary)\n",
    "* Use the exact same optimizer configuration you used for Part 1 of this lab (learning rate $0.05$, etc).\n",
    "* Use mini-batch training like you did in Lab 4, with a batch size of $100$.\n",
    "* Train for 5 epochs (5 passes over the full training set)\n",
    "\n",
    "First, define the loss function and optimizer in a separate code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_epoch = 5\n",
    "\n",
    "# Your code to define loss function and optimizer here. Aim for 2 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, write your training loop in a separate code cell below, so that you can re-run this code cell to \"continue\" training with the same optimizer object, if you want to train your model longer.\n",
    "\n",
    "I recommend you add a print statement to report progress like we did in Lab 4, such as:\n",
    "```\n",
    "Epoch 1 final minibatch had loss 0.2452\n",
    "Epoch 2 final minibatch had loss 0.2077\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your mini-batch training loop here. Aim for 10-12 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot your trained model's predictions**. The predictions should look like before, now matching the targets better than before training. \n",
    "\n",
    "<img src=\"img/mnist_predictions.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here. Aim for 2-3 lines. Re-use the y_true matrix from the earlier code cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you only trained your ConvNet for 5 epochs total, you should be able to identify at least one training case that appears to be \"harder\" than the others, *i.e.* the model has a harder time giving a confident prediction. For example, here is an easy \"9\" and a hard \"9\" side by side:\n",
    "![image](img/easy_and_hard.png)\n",
    "\n",
    "**Plot an 'easy' training example and a 'hard' training example side-by-side** using the *plot_matrix_grid* function. This will require you to pull out two separate rows of *X_trn* and turn them (together) into a tensor with shape (2,28,28) so that the *plot_matrix_grid* knows what to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here. Aim for 1-4 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspect your trained model's filters** by plotting them with the *plot_matrix_grid* function. They should no longer be completely random and instead contain structures that look like little \"edge\" detectors, such as the \"diagonal line\" detector shown below\n",
    "![image](img/mnist_trained_filters.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Your code here. Aim for 2-3 lines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
